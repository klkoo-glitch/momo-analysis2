import streamlit as st
import pandas as pd
import os
import shutil
from datetime import datetime, timedelta
import io

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ëª¨ëª¨ìœ ë¶€ ì—‘ì…€ ë°ì´í„° ì¶”ì¶œê¸°", layout="wide")
st.title("ğŸ“‚ ëª¨ëª¨ìœ ë¶€ ì§€ì ë³„ í†µí•© ë°ì´í„° ì¶”ì¶œ (ì—‘ì…€ ì¶”ì¶œìš©)")

# íŒŒì¼ ê²½ë¡œ
file_path = 'ì§€ì ë³„ ìƒ˜í”ŒëŸ¬ìŠ¤ ë°ì´í„°_2025.12.29.xlsx'
DUPLICATE_LIMIT = 30 

@st.cache_data(ttl=600)
def process_data_for_excel():
    if not os.path.exists(file_path): 
        return None, "FILE_NOT_FOUND"
    
    temp_path = "temp_export_final.xlsx"
    try:
        shutil.copyfile(file_path, temp_path)
        excel = pd.ExcelFile(temp_path)
        combined_data = []
        
        def unify_name(x):
            txt = str(x)
            if 'ê°•ë‚¨êµ¬ì²­' in txt: return 'ê°•ë‚¨êµ¬ì²­'
            if 'ê¸°í¥' in txt: return 'ê¸°í¥'
            if 'ì—¬ì˜ë„' in txt or 'ë¸Œë¼ì´íŠ¼' in txt: return 'ì—¬ì˜ë„'
            if 'ëª©ë™' in txt: return 'ëª©ë™'
            if 'ì›ì£¼' in txt: return 'ì›ì£¼'
            if 'ê°•ë‚¨' in txt: return 'ê°•ë‚¨'
            return "ê¸°íƒ€"

        for sheet in excel.sheet_names:
            if any(x in sheet for x in ['ìš”ì•½', 'ê³µì‹']): continue
            df_sheet = pd.read_excel(temp_path, sheet_name=sheet, skiprows=3)
            if df_sheet.empty: continue
            
            is_shifted = df_sheet['ê°€ë§¹ì ëª…'].astype(str).str.match(r'\d{4}[-./]\d{2}[-./]\d{2}')
            
            normal = df_sheet[~is_shifted].copy()
            if not normal.empty:
                req = ['ì¹´ë“œë²ˆí˜¸', 'ê±°ë˜ê¸ˆì•¡', 'ê±°ë˜ì¼ì', 'ê±°ë˜ì‹œê°„', 'ê°€ë§¹ì ëª…', 'ê±°ë˜ìœ í˜•']
                cols = [c for c in req if c in normal.columns]
                tmp = normal[cols].copy()
                tmp['ê°€ë§¹ì ëª…'] = tmp['ê°€ë§¹ì ëª…'].apply(unify_name)
                combined_data.append(tmp)
            
            shifted = df_sheet[is_shifted].copy()
            if not shifted.empty:
                sh = pd.DataFrame()
                sh['ì¹´ë“œë²ˆí˜¸'] = shifted['ì²´í¬']; sh['ê±°ë˜ê¸ˆì•¡'] = shifted['ë´‰ì‚¬ë£Œ']
                sh['ê±°ë˜ì¼ì'] = shifted['ê°€ë§¹ì ëª…']; sh['ê±°ë˜ì‹œê°„'] = shifted['ë°œê¸‰ì‚¬']
                sh['ê±°ë˜ìœ í˜•'] = shifted['ì¹´ë“œë²ˆí˜¸']; sh['ê°€ë§¹ì ëª…'] = unify_name(sheet)
                combined_data.append(sh)
        
        full_df = pd.concat(combined_data, sort=False).reset_index(drop=True)
        full_df['ê±°ë˜ê¸ˆì•¡'] = pd.to_numeric(full_df['ê±°ë˜ê¸ˆì•¡'].astype(str).str.replace(',', ''), errors='coerce').fillna(0)
        # ì·¨ì†Œë¶„ ë³´ì • ë¡œì§
        full_df['net_sales'] = full_df.apply(lambda x: -x['ê±°ë˜ê¸ˆì•¡'] if str(x.get('ê±°ë˜ìœ í˜•', '')) == 'ì·¨ì†Œ' else x['ê±°ë˜ê¸ˆì•¡'], axis=1)
        
        full_df['datetime'] = pd.to_datetime(full_df['ê±°ë˜ì¼ì'].astype(str).str.split(' ').str[0] + ' ' + full_df['ê±°ë˜ì‹œê°„'].astype(str).fillna('00:00:00'), errors='coerce')
        full_df = full_df.dropna(subset=['datetime', 'ì¹´ë“œë²ˆí˜¸'])
        full_df = full_df.sort_values(['ê°€ë§¹ì ëª…', 'ì¹´ë“œë²ˆí˜¸', 'datetime'])
        
        # ì¤‘ë³µ ì œê±° (30ë¶„)
        full_df['time_diff'] = full_df.groupby(['ê°€ë§¹ì ëª…', 'ì¹´ë“œë²ˆí˜¸'])['datetime'].diff().dt.total_seconds() / 60.0
        full_df = full_df[~((full_df['time_diff'] <= DUPLICATE_LIMIT) & (full_df['time_diff'].notnull()))]
        
        # ê³ ê° í–‰ë™ ë°ì´í„°
        full_df['visit_no'] = full_df.groupby(['ê°€ë§¹ì ëª…', 'ì¹´ë“œë²ˆí˜¸']).cumcount() + 1
        full_df['first_v'] = full_df.groupby(['ê°€ë§¹ì ëª…', 'ì¹´ë“œë²ˆí˜¸'])['datetime'].transform('min')
        full_df['last_v'] = full_df.groupby(['ê°€ë§¹ì ëª…', 'ì¹´ë“œë²ˆí˜¸'])['datetime'].transform('max')
        full_df['total_v_all'] = full_df.groupby(['ê°€ë§¹ì ëª…', 'ì¹´ë“œë²ˆí˜¸'])['datetime'].transform('count')
        
        second_v = full_df[full_df['visit_no'] == 2][['ê°€ë§¹ì ëª…', 'ì¹´ë“œë²ˆí˜¸', 'datetime']]
        second_v.columns = ['ê°€ë§¹ì ëª…', 'ì¹´ë“œë²ˆí˜¸', 'second_date']
        full_df = full_df.merge(second_v, on=['ê°€ë§¹ì ëª…', 'ì¹´ë“œë²ˆí˜¸'], how='left')
        full_df['ì—°ì›”'] = full_df['datetime'].dt.strftime('%Y-%m')
        
        return full_df, "SUCCESS"
    except Exception as e: return None, str(e)

df_main, status = process_data_for_excel()

if status == "SUCCESS" and df_main is not None:
    stores = [s for s in sorted(df_main['ê°€ë§¹ì ëª…'].unique()) if s != "ê¸°íƒ€"]
    data_end_date = df_main['datetime'].max()
    all_months = sorted(df_main['ì—°ì›”'].unique())

    all_store_metrics = []

    for s in stores:
        s_data = df_main[df_main['ê°€ë§¹ì ëª…'] == s]
        
        metrics_rows = {
            "ë§¤ì¶œì•¡": {"ë§¤ì¥": s, "í•­ëª©": "ë§¤ì¶œì•¡"},
            "ì „ì²´ ë°©ë¬¸ììˆ˜": {"ë§¤ì¥": s, "í•­ëª©": "ì „ì²´ ë°©ë¬¸ììˆ˜"},
            "ì‹ ê·œ ë°©ë¬¸ììˆ˜": {"ë§¤ì¥": s, "í•­ëª©": "ì‹ ê·œ ë°©ë¬¸ììˆ˜"},
            "ì‹ ê·œë¹„ìœ¨(%)": {"ë§¤ì¥": s, "í•­ëª©": "ì‹ ê·œë¹„ìœ¨(%)"},
            "ì¬ë°©ë¬¸ììˆ˜": {"ë§¤ì¥": s, "í•­ëª©": "ì¬ë°©ë¬¸ììˆ˜"},
            "ì¬ë°©ë¬¸ìë¹„ìœ¨(%)": {"ë§¤ì¥": s, "í•­ëª©": "ì¬ë°©ë¬¸ìë¹„ìœ¨(%)"},
            "ì ì¬ ë‹¨ê³¨(2~3íšŒ)": {"ë§¤ì¥": s, "í•­ëª©": "ì ì¬ ë‹¨ê³¨(2~3íšŒ)"},
            "ì¶©ì„±ê³ ê°(4íšŒì´ìƒ)": {"ë§¤ì¥": s, "í•­ëª©": "ì¶©ì„±ê³ ê°(4íšŒì´ìƒ)"},
            "ì¶©ì„±ê³ ê°ë¹„ìœ¨(%)": {"ë§¤ì¥": s, "í•­ëª©": "ì¶©ì„±ê³ ê°ë¹„ìœ¨(%)"},
            "ì „ì²´ ì „í™˜ìœ¨(%)": {"ë§¤ì¥": s, "í•­ëª©": "ì „ì²´ ì „í™˜ìœ¨(%)"},
            "3ê°œì›” ì „í™˜ìœ¨(%)": {"ë§¤ì¥": s, "í•­ëª©": "3ê°œì›” ì „í™˜ìœ¨(%)"},
            "ë°©ë¬¸ë¹ˆë„": {"ë§¤ì¥": s, "í•­ëª©": "ë°©ë¬¸ë¹ˆë„"},
            "ì´íƒˆìœ¨(%)": {"ë§¤ì¥": s, "í•­ëª©": "ì´íƒˆìœ¨(%)"},
            "ìœ ì§€ê¸°ê°„": {"ë§¤ì¥": s, "í•­ëª©": "ìœ ì§€ê¸°ê°„"}
        }

        for m in all_months:
            m_df = s_data[s_data['ì—°ì›”'] == m]
            if m_df.empty:
                for k in metrics_rows.keys(): metrics_rows[k][m] = 0
                continue
            
            v_ids = m_df['ì¹´ë“œë²ˆí˜¸'].unique()
            total_v = len(v_ids)
            new_v_ids = m_df[m_df['first_v'].dt.strftime('%Y-%m') == m]['ì¹´ë“œë²ˆí˜¸'].unique()
            new_v = len(new_v_ids)
            
            if new_v > 0:
                new_cust_full = s_data[s_data['ì¹´ë“œë²ˆí˜¸'].isin(new_v_ids)].groupby('ì¹´ë“œë²ˆí˜¸').first()
                o_conv = round(len(new_cust_full[new_cust_full['total_v_all'] >= 2]) / new_v * 100, 1)
                c_3m = round(len(new_cust_full[(new_cust_full['second_date'].notnull()) & (new_cust_full['second_date'] <= new_cust_full['first_v'] + timedelta(days=90))]) / new_v * 100, 1)
            else: o_conv = c_3m = 0.0

            v_stats = s_data[s_data['ì¹´ë“œë²ˆí˜¸'].isin(v_ids)].groupby('ì¹´ë“œë²ˆí˜¸').first()
            loyal_v = len(v_stats[v_stats['total_v_all'] >= 4])
            poten_v = len(v_stats[(v_stats['total_v_all'] >= 2) & (v_stats['total_v_all'] <= 3)])
            ret_pool = v_stats[v_stats['total_v_all'] >= 2]

            metrics_rows["ë§¤ì¶œì•¡"][m] = int(m_df['net_sales'].sum())
            metrics_rows["ì „ì²´ ë°©ë¬¸ììˆ˜"][m] = total_v
            metrics_rows["ì‹ ê·œ ë°©ë¬¸ììˆ˜"][m] = new_v
            metrics_rows["ì‹ ê·œë¹„ìœ¨(%)"][m] = round(new_v/total_v*100, 1) if total_v > 0 else 0
            metrics_rows["ì¬ë°©ë¬¸ììˆ˜"][m] = total_v - new_v
            metrics_rows["ì¬ë°©ë¬¸ìë¹„ìœ¨(%)"][m] = round((total_v-new_v)/total_v*100, 1) if total_v > 0 else 0
            metrics_rows["ì ì¬ ë‹¨ê³¨(2~3íšŒ)"][m] = poten_v
            metrics_rows["ì¶©ì„±ê³ ê°(4íšŒì´ìƒ)"][m] = loyal_v
            metrics_rows["ì¶©ì„±ê³ ê°ë¹„ìœ¨(%)"][m] = round(loyal_v/total_v*100, 1) if total_v > 0 else 0
            metrics_rows["ì „ì²´ ì „í™˜ìœ¨(%)"][m] = o_conv
            metrics_rows["3ê°œì›” ì „í™˜ìœ¨(%)"][m] = c_3m
            metrics_rows["ë°©ë¬¸ë¹ˆë„"][m] = round(ret_pool['total_v_all'].mean(), 1) if not ret_pool.empty else 1.0
            metrics_rows["ì´íƒˆìœ¨(%)"][m] = round(len(ret_pool[ret_pool['last_v'] <= data_end_date - timedelta(days=90)]) / len(ret_pool) * 100, 1) if not ret_pool.empty else 0
            metrics_rows["ìœ ì§€ê¸°ê°„"][m] = round((ret_pool['last_v'] - ret_pool['first_v']).dt.days.mean(), 1) if not ret_pool.empty else 0

        for row in metrics_rows.values():
            all_store_metrics.append(row)

    final_df = pd.DataFrame(all_store_metrics)
    st.subheader("ğŸ“Š ì§€ì ë³„ ì›”ê°„ í†µí•© ë¶„ì„ ë°ì´í„°")
    st.dataframe(final_df, use_container_width=True)

    buffer = io.BytesIO()
    with pd.ExcelWriter(buffer, engine='xlsxwriter') as writer:
        final_df.to_excel(writer, index=False, sheet_name='Sheet1')
    
    st.download_button(
        label="ğŸ“‚ ë³´ì •ëœ í†µí•© ì—‘ì…€ ë‹¤ìš´ë¡œë“œ",
        data=buffer.getvalue(),
        file_name=f"ëª¨ëª¨ìœ ë¶€_ë³´ì •ë°ì´í„°_{datetime.now().strftime('%Y%m%d')}.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )
else:

    st.error(f"ì˜¤ë¥˜: {status}")
